{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Use Watsonx to respond to natural language questions using RAG approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please note that for the watsonx challenge, please run these notebooks locally on your laptop/desktop and do not run it in IBM Cloud.  The instructions for running the notebook locally are provided in the readme.md file present in the zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook contains the steps and code to demonstrate support of Retrieval Augumented Generation in watsonx.ai. It introduces commands for data retrieval, knowledge base building & querying, and model testing.\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
    "\n",
    "#### About Retrieval Augmented Generation\n",
    "Retrieval Augmented Generation (RAG) is a versatile pattern that can unlock a number of use cases requiring factual recall of information, such as querying a knowledge base in natural language.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Index knowledge base passages (once)\n",
    "- Retrieve relevant passage(s) from knowledge base (for every user query)\n",
    "- Generate a response by feeding retrieved passage into a large language model (for every user query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"setup\"></a>\n",
    "##  Set up the environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb==0.3.27 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (2.31.0)\n",
      "Requirement already satisfied: pydantic==1.9 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (1.9.0)\n",
      "Requirement already satisfied: hnswlib>=0.7 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.6.8)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.8.1)\n",
      "Requirement already satisfied: fastapi==0.85.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.85.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (1.25.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (4.7.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (1.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from chromadb==0.3.27) (7.3.1)\n",
      "Requirement already satisfied: starlette==0.20.4 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastapi==0.85.1->chromadb==0.3.27) (0.20.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.27) (3.7.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (2023.7.22)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (6.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (1.26.16)\n",
      "Requirement already satisfied: pytz in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (2023.3)\n",
      "Requirement already satisfied: zstandard in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (0.21.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.27) (4.3.2)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.27) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.27) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.27) (23.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.27) (4.23.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb==0.3.27) (1.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.3->chromadb==0.3.27) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.27) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.27) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from posthog>=2.4.0->chromadb==0.3.27) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.28->chromadb==0.3.27) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.28->chromadb==0.3.27) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.65.0->chromadb==0.3.27) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (8.1.6)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (6.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.27) (11.0.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.27) (10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata->clickhouse-connect>=0.5.7->chromadb==0.3.27) (3.16.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.3.27) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.27) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.27) (1.1.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb==0.3.27) (3.4.1)\n",
      "Requirement already satisfied: sentence_transformers in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence_transformers) (10.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: rouge_score in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.25.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Requirement already satisfied: nltk in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: ibm-watson-machine-learning>=1.0.312 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.312)\n",
      "Requirement already satisfied: requests in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (2.31.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (1.26.16)\n",
      "Requirement already satisfied: pandas<1.6.0,>=0.24.2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (1.5.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (2023.7.22)\n",
      "Requirement already satisfied: lomond in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (0.3.3)\n",
      "Requirement already satisfied: tabulate in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (0.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (23.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (6.8.0)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-watson-machine-learning>=1.0.312) (2.13.1)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.13.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.312) (2.13.1)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.13.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.312) (2.13.1)\n",
      "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.312) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ibm-cos-sdk-core==2.13.1->ibm-cos-sdk<2.14.0,>=2.12.0->ibm-watson-machine-learning>=1.0.312) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning>=1.0.312) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas<1.6.0,>=0.24.2->ibm-watson-machine-learning>=1.0.312) (1.25.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->ibm-watson-machine-learning>=1.0.312) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->ibm-watson-machine-learning>=1.0.312) (3.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from importlib-metadata->ibm-watson-machine-learning>=1.0.312) (3.16.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\003l24744\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from lomond->ibm-watson-machine-learning>=1.0.312) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb==0.3.27\n",
    "!pip install sentence_transformers\n",
    "!pip install pandas\n",
    "!pip install rouge_score\n",
    "!pip install nltk\n",
    "!pip install \"ibm-watson-machine-learning>=1.0.312\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please restart the notebook kernel to pick up proper version of packages installed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "import pandas as pd\n",
    "from typing import Optional, Dict, Any, Iterable, List\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import sentence_transformers: Please install sentence-transformers package.\")\n",
    "    \n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.api.types import EmbeddingFunction\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import chromdb: Please install chromadb package.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud user API key. For details, see\n",
    "[documentation](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": \"6BRv7jXYCVKwfMolURF89jgWWAQPZg7tur_EbGUWo6Uf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The API requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id.\n",
    "\n",
    "**Hint**: You can find the `project_id` as follows. Open the prompt lab in watsonx.ai. At the very top of the UI, there will be `Projects / <project name> /`. Click on the `<project name>` link. Then get the `project_id` from Project's Manage tab (Project -> Manage -> General -> Details).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    project_id = \"ba443f74-4a4e-4bad-a841-5b211ce0d7c8\"\n",
    "except KeyError:\n",
    "    project_id = \"ba443f74-4a4e-4bad-a841-5b211ce0d7c8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"data\"></a>\n",
    "## Train/test data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load train and test datasets. At first, training dataset (`train_data`) should be used to work with the models to prepare and tune prompt. Then, test dataset (`test_data`) should be used to calculate the metrics score for selected model, defined prompts and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_test = 'Downloads/watsonx_challenge_evaluation_notebooks/data/RAG/nq910_400_instances/test.tsv'\n",
    "filename_train = 'Downloads/watsonx_challenge_evaluation_notebooks/data/RAG/nq910_400_instances/train.tsv'\n",
    "\n",
    "test_data_dict = pd.read_csv(filename_test, delimiter='\\t')\n",
    "train_data = pd.read_csv(filename_train, delimiter='\\t')\n",
    "test_data = pd.DataFrame(test_data_dict)\n",
    "new_rows=[{\"answers\": \"Redwood\", \"question\": \"Where was carter born?\",\"qid\":'123',\"relevant\":'267'} , \n",
    "         {\"answers\": \"\", \"question\": \"which school did chris carter played basketball?\",\"qid\":'124',\"relevant\":'267'}]\n",
    "new_data = pd.DataFrame(new_rows)\n",
    "test_data = pd.concat([test_data, new_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8519</td>\n",
       "      <td>when was the cathedral of santa maria del fior...</td>\n",
       "      <td>136</td>\n",
       "      <td>begun in 1296::completed by 1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852</td>\n",
       "      <td>who plays cassidy on law and order svu</td>\n",
       "      <td>177</td>\n",
       "      <td>Dean Winters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7600</td>\n",
       "      <td>who was the old woman in phantom of the opera</td>\n",
       "      <td>642</td>\n",
       "      <td>Madame Giry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4258</td>\n",
       "      <td>when is the finals of americas got talent 2017</td>\n",
       "      <td>781</td>\n",
       "      <td>September 20 , 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8272</td>\n",
       "      <td>who played the frog in gnomeo and juliet</td>\n",
       "      <td>1018</td>\n",
       "      <td>Ashley Jensen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                           question relevant  \\\n",
       "0  8519  when was the cathedral of santa maria del fior...      136   \n",
       "1   852             who plays cassidy on law and order svu      177   \n",
       "2  7600      who was the old woman in phantom of the opera      642   \n",
       "3  4258     when is the finals of americas got talent 2017      781   \n",
       "4  8272           who played the frog in gnomeo and juliet     1018   \n",
       "\n",
       "                            answers  \n",
       "0  begun in 1296::completed by 1436  \n",
       "1                      Dean Winters  \n",
       "2                       Madame Giry  \n",
       "3               September 20 , 2017  \n",
       "4                     Ashley Jensen  "
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question</th>\n",
       "      <th>relevant</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5555</td>\n",
       "      <td>who did chris carter play for last year</td>\n",
       "      <td>267</td>\n",
       "      <td>Milwaukee Brewers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6654</td>\n",
       "      <td>what is the latest version of safari on mac</td>\n",
       "      <td>664</td>\n",
       "      <td>Safari 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3396</td>\n",
       "      <td>when did bucharest become the capital of romania</td>\n",
       "      <td>944</td>\n",
       "      <td>1862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8198</td>\n",
       "      <td>who did jeffrey dean morgan play on supernatural</td>\n",
       "      <td>1398</td>\n",
       "      <td>John Eric Winchester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4526</td>\n",
       "      <td>who is the shortest man that ever lived</td>\n",
       "      <td>1522</td>\n",
       "      <td>Chandra Bahadur Dangi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                          question relevant  \\\n",
       "0  5555           who did chris carter play for last year      267   \n",
       "1  6654       what is the latest version of safari on mac      664   \n",
       "2  3396  when did bucharest become the capital of romania      944   \n",
       "3  8198  who did jeffrey dean morgan play on supernatural     1398   \n",
       "4  4526           who is the shortest man that ever lived     1522   \n",
       "\n",
       "                 answers  \n",
       "0      Milwaukee Brewers  \n",
       "1              Safari 11  \n",
       "2                   1862  \n",
       "3   John Eric Winchester  \n",
       "4  Chandra Bahadur Dangi  "
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build up knowledge base\n",
    "\n",
    "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
    "\n",
    "We can generate dense vector representations using embedding models. In this notebook, we use [SentenceTransformers](https://www.google.com/search?client=safari&rls=en&q=sentencetransformers&ie=UTF-8&oe=UTF-8) [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) to embed both the knowledge base passages and user queries. `all-MiniLM-L6-v2` is a performant open-source model that is small enough to run locally.\n",
    "\n",
    "A vector database is optimized for dense vector indexing and retrieval. This notebook uses [Chroma](https://docs.trychroma.com), a user-friendly open-source vector database, licensed under Apache 2.0, which offers good speed and performance with all-MiniLM-L6-v2 embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The dataset we are using is already split into self-contained passages that can be ingested by Chroma. \n",
    "\n",
    "The size of each passage is limited by the embedding model's context window (which is 256 tokens for `all-MiniLM-L6-v2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load knowledge base documents\n",
    "\n",
    "Load set of documents used further to build knowledge base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/knowledge_base\n"
     ]
    }
   ],
   "source": [
    "data_root = \"data\"\n",
    "knowledge_base_dir = f\"{data_root}/knowledge_base\"\n",
    "print(knowledge_base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(knowledge_base_dir):\n",
    "    from zipfile import ZipFile\n",
    "    with ZipFile(knowledge_base_dir + \".zip\", 'r') as zObject:\n",
    "        zObject.extractall(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv(\"Downloads/knowledge_base/knowledge_base/psgs.tsv\", sep='\\t', header=0)\n",
    "documents['indextext'] = documents['title'].astype(str) + \"\\n\" + documents['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create an embedding function\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by chromadb. The performance of chromadb may differ depending on the embedding model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_func = MiniLML6V2EmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Set up Chroma upsert\n",
    "\n",
    "Upserting a document means update the document even if it exists in the database. Otherwise re-inserting a document throws an error. This is useful for experimentation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ChromaWithUpsert:\n",
    "    def __init__(\n",
    "            self,\n",
    "            name: Optional[str] = \"watsonx_rag_collection\",\n",
    "            persist_directory:Optional[str]=None,\n",
    "            embedding_function: Optional[EmbeddingFunction]=None,\n",
    "            collection_metadata: Optional[Dict] = None,\n",
    "    ):\n",
    "        self._client_settings = chromadb.config.Settings()\n",
    "        if persist_directory is not None:\n",
    "            self._client_settings = chromadb.config.Settings(\n",
    "                chroma_db_impl=\"duckdb+parquet\",\n",
    "                persist_directory=persist_directory,\n",
    "            )\n",
    "        self._client = chromadb.Client(self._client_settings)\n",
    "        self._embedding_function = embedding_function\n",
    "        self._persist_directory = persist_directory\n",
    "        self._name = name\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=self._name,\n",
    "            embedding_function=self._embedding_function\n",
    "            if self._embedding_function is not None\n",
    "            else None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "\n",
    "    def upsert_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadata: Optional[List[dict]] = None,\n",
    "        ids: Optional[List[str]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "        Args:\n",
    "            :param texts (Iterable[str]): Texts to add to the vectorstore.\n",
    "            :param metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
    "            :param ids (Optional[List[str]], optional): Optional list of IDs.\n",
    "            :param metadata: Optional[List[dict]] - optional metadata (such as title, etc.)\n",
    "        Returns:\n",
    "            List[str]: List of IDs of the added texts.\n",
    "        \"\"\"\n",
    "        # TODO: Handle the case where the user doesn't provide ids on the Collection\n",
    "        if ids is None:\n",
    "            import uuid\n",
    "            ids = [str(uuid.uuid1()) for _ in texts]\n",
    "        embeddings = None\n",
    "        self._collection.upsert(\n",
    "            metadatas=metadata, documents=texts, ids=ids\n",
    "        )\n",
    "        return ids\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._collection.count()==0\n",
    "\n",
    "    def persist(self):\n",
    "        self._client.persist()\n",
    "\n",
    "    def query(self, query_texts:str, n_results:int=5):\n",
    "        \"\"\"\n",
    "        Returns the closests vector to the question vector\n",
    "        :param query_texts: the question\n",
    "        :param n_results: number of results to generate\n",
    "        :return: the closest result to the given question\n",
    "        \"\"\"\n",
    "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Embed and index documents with Chroma\n",
    "\n",
    "**Note: Could take several minutes if you don't have pre-built indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 500 ms\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chroma = ChromaWithUpsert(\n",
    "    name=f\"nq910_minilm6v2\",\n",
    "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
    "    persist_directory=knowledge_base_dir,\n",
    ")\n",
    "if chroma.is_empty():\n",
    "    _ = chroma.upsert_texts(\n",
    "        texts=documents.indextext.tolist(),\n",
    "        # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "        metadata=[{'title': title, 'id': id}\n",
    "                  for (title,id) in\n",
    "                  zip(documents.title, documents.id)],  # filter on these!\n",
    "        ids=[str(i) for i in documents.id],  # unique for each doc\n",
    "    )\n",
    "    chroma.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"models\"></a>\n",
    "## Foundation Models on Watsonx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You need to specify `model_id` that will be used for inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Action**: Use `FLAN_UL2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = ModelTypes.FLAN_UL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"predict\"></a>\n",
    "## Generate a retrieval-augmented response to a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select questions\n",
    "\n",
    "Get questions from the previously loaded test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who did chris carter play for last year?\n",
      "what is the latest version of safari on mac?\n",
      "when did bucharest become the capital of romania?\n",
      "who did jeffrey dean morgan play on supernatural?\n",
      "who is the shortest man that ever lived?\n",
      "how many seconds do you have to throw a grenade?\n",
      "who is known as a father of indian cricket?\n",
      "what is the name of the period in japanese history that began in 1868?\n",
      "harold and kumar go to white castle where was it filmed?\n",
      "how many games have the capitals won in the playoffs?\n",
      "what is the best selling nintendo game of all time?\n",
      "korean movie about a man on an island?\n",
      "who plays lorelai in hannah montana the movie?\n",
      "what season of greys anatomy was the plane crash?\n",
      "who made call of duty black ops 2?\n",
      "when was the last solar eclipse seen in north america?\n",
      "who is hosting the fifa world cup in 2022?\n",
      "what is the record for wins in major league baseball?\n",
      "big boss 2 telugu set location in hyderabad?\n",
      "who did the us support in the korean war?\n",
      "what is the caterpillar smoking in alice in wonderland?\n",
      "how much aid does us give to other countries?\n",
      "who plays jake on two and a half?\n",
      "what do you call a bundle of hay?\n",
      "how many levels are there in science olympiad?\n",
      "where are the singers of florida georgia line from?\n",
      "who sings lead on wouldnt it be nice?\n",
      "who is the main character in shadow of mordor?\n",
      "where are the next olympics to be held?\n",
      "when did game of thrones season 7 start?\n",
      "when does hook show up in once upon a time?\n",
      "when was the last time georgia tech won a national championship?\n",
      "who plays victor in days of our lives?\n",
      "who won the last triple crown in baseball?\n",
      "when does the football transfer window open in 2018?\n",
      "what episode of mr young do adam and echo kiss?\n",
      "when is game of thrones season 7 episode 7 releasing?\n",
      "who is the architect of sheikh zayed mosque?\n",
      "who is the director of iron man 3?\n",
      "who is one of the first german composers that we know about?\n",
      "where do they move to in cheaper by the dozen?\n",
      "who played bass on and justice for all?\n",
      "zen and the art of motorcycle maintenance bikes?\n",
      "when did texas become part of united states?\n",
      "the atlantoaxial joint is an example of what type of joint?\n",
      "what is the fastest roller coaster in california?\n",
      "when did they start to build the great wall of china?\n",
      "what type of reaction is the rusting of iron?\n",
      "where do the flyers play their home games?\n",
      "where does something old something new something borrowed something blue come from?\n",
      "Where was carter born?\n",
      "which school did chris carter played basketball?\n"
     ]
    }
   ],
   "source": [
    "question_texts = [q.strip(\"?\") + \"?\" for q in test_data['question'].tolist()]\n",
    "print(\"\\n\".join(question_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Retrieve relevant context\n",
    "\n",
    "Fetch paragraphs similar to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "relevant_contexts = []\n",
    "\n",
    "for question_text in question_texts:\n",
    "    relevant_chunks = chroma.query(\n",
    "        query_texts=[question_text],\n",
    "        n_results=6,\n",
    "    )\n",
    "    relevant_contexts.append(relevant_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get the set of chunks for one of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Paragraph index :  268\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "2.2 Oakland Athletics 2.3 Houston Astros 2.4 Milwaukee Brewers 2.5 New York Yankees 2.6 Return to the Oakland Athletics 3 Personal life 4 References 5 External links Early life and career ( edit ) Carter was born in Redwood City , California . At approximately age 7 or 8 , his family moved to Las Vegas . He attended Sierra Vista High School . In 2005 , Sierra Vista 's baseball team won the Nevada Interscholastic Activities Association Class 4A state championship . Professional career ( edit ) Draft and minors ( edit ) Carter was drafted by the Chicago White Sox in the 15th round of the 2005 Major League Baseball Draft . Carter began his professional career with the Bristol White Sox of the Rookie - level Appalachian League in 2005 . He hit 10 home runs and had 37 runs batted in ( RBIs ) . He played for two teams in the 2006 season . The teams included the Great Falls White Sox of the Rookie - level Pioneer League and the Kannapolis Intimidators of the Class A South Atlantic League . He had a combined total of 16 home runs and 63 RBIs . He played for Kannapolis in the 2007 season where he hit 25 home runs and had 93 RBIs . During the 2007 offseason , the White Sox traded Carter to the Arizona Diamondbacks for Carlos Quentin . Carter with the Athletics in 2012 Oakland Athletics ( edit ) Two weeks after\n",
      "Distance :  0.6766288876533508\n",
      "=========\n",
      "Paragraph index :  272\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      ", the New York Yankees signed Carter to a one - year contract , worth $3.5 million . Carter batted . 204 with eight home runs and 70 strikeouts before the Yankees designated him for assignment on June 24 . He was called back up by the Yankees on June 29 when his replacement at first base , Tyler Austin , landed on the disabled list . On July 4 , he was again designated for assignment , this time to make room for Ji - man Choi on the roster . He was released on July 10 . Return to the Oakland Athletics ( edit ) Carter signed a minor league contract with the Oakland Athletics on July 21 , 2017 , and was assigned to the Nashville Sounds of the PCL . Personal life ( edit ) Carter 's father , Vernon , played basketball for Rancho High School in North Las Vegas . Carter is a car enthusiast . He owns a Shelby Super Snake . References ( edit ) ^ Jump up to : `` Get to Know : Brewers first baseman Chris Carter '' . Retrieved February 17 , 2017 . ^ Jump up to : `` Powerful Carter always had a single focus '' . Retrieved February 17 , 2017 . Jump up ^ Merkin , Scott ( December 3 , 2007 ) . `` White Sox trade for outfielder Quentin '' . Chicago White Sox . Retrieved July 16 , 2008 . Jump\n",
      "Distance :  0.6858607530593872\n",
      "=========\n",
      "Paragraph index :  269\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "he was traded to Arizona , the Diamondbacks traded Carter , Carlos Gonzlez , Brett Anderson , Aaron Cunningham , Greg Smith , and Dana Eveland to the Oakland Athletics for Dan Haren and Connor Robertson . He played for the Stockton Ports of the Class A-Advanced California League in the 2008 season where he hit 39 home runs and had 104 RBIs . Carter was named the California League Rookie of the Year for the 2008 season . In 2009 , Carter split time between the Midland RockHounds of the Class AA Texas League and the Sacramento River Cats of the Class AAA Pacific Coast League ( PCL ) , putting a . 329 batting average ( a 70 - point increase from 2008 ) , 28 homers and 115 RBIs combined . In 2008 and 2009 , Baseball America ranked Carter as one of the top 10 prospects in the Athletics ' organization . Also in 2008 and 2009 , Carter was the Oakland Athletics ' Minor League Player of Year . Carter was placed on the A 's 40 - man roster on November 20 , 2009 . In 2009 , he was named the This Year in Minor League Baseball Awards `` Overall Hitter of The Year '' . On August 9 , 2010 , Carter was promoted to Oakland and went 0 -- for -- 3 in his first game . On August 16 , Carter was demoted to Sacramento after starting his career 0\n",
      "Distance :  0.7151551246643066\n",
      "=========\n",
      "Paragraph index :  271\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "slower for Carter , as he batted only . 153 throughout the entire month of April . Carter would turn his fortunes around after the All - Star break though , as finished with a . 227 batting average and career highs of 37 home runs and 88 RBI . On January 14 , 2015 , Carter and the Astros agreed to a one - year contract worth $4.175 million , avoiding arbitration . Carter had a disappointing 2015 season for the Astros ; Carter was the team 's starting first baseman , but hit only . 199 in 129 games . However , he still managed to hit 24 home runs , and then hit . 294 with a home run against the Kansas City Royals during the 2015 American League Division Series . At the conclusion of the 2015 season Carter was non tendered by the Astros and he became a free agent . Milwaukee Brewers ( edit ) On January 6 , 2016 , Carter signed a one - year , $2.5 million contract with the Milwaukee Brewers . He posted a . 321 on - base percentage and hit 41 home runs , leading the National League in 2016 . However , he had a . 222 batting average and led the league with 206 strikeouts . The Brewers did not tender Carter a contract for the 2017 , making him a free agent . New York Yankees ( edit ) On February 16 , 2017\n",
      "Distance :  0.8088639974594116\n",
      "=========\n",
      "Paragraph index :  275\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "External links ( edit ) Wikimedia Commons has media related to Chris Carter ( baseball player born 1986 ) . Career statistics and player information from MLB , or Baseball - Reference , or Fangraphs , or The Baseball Cube , or Baseball - Reference ( Minors ) ( hide ) National League season home run leaders 1876 : Hall 1877 : Pike 1878 : Hines 1879 : C. Jones 1880 : Stovey & O'Rourke 1881 : Brouthers 1882 : Wood 1883 : Ewing 1884 : Williamson 1885 : Dalrymple 1886 : Brouthers & Richardson 1887 : O'Brien 1888 : Ryan 1889 : Thompson 1890 : Burns , Tiernan & Wilmot 1891 : Tiernan & Stovey 1892 : Holliday 1893 : Delahanty 1894 : Duffy 1895 : Thompson 1896 : Joyce & Delahanty 1897 : Duffy 1898 : J. Collins 1899 : Freeman 1900 : Long 1901 : Crawford 1902 : Leach 1903 : Sheckard 1904 : Lumley 1905 : Odwell 1906 : Jordan 1907 : Brain 1908 : Jordan 1909 : Murray 1910 : Schulte & Beck 1911 : Schulte 1912 : Zimmerman 1913 : Cravath 1914 : Cravath 1915 : Cravath 1916 : C. Williams & Robertson 1917 : Cravath & Robertson 1918 : Cravath 1919 : Cravath 1920 : C. Williams 1921 : Kelly 1922 : Hornsby 1923 : C. Williams 1924 : Fournier 1925 : Hornsby 1926 : Wilson 1927 : C. Williams & Wilson 1928 : Wilson & Bottomley 1929 : Klein 1930 : Wilson\n",
      "Distance :  0.8511187434196472\n",
      "=========\n",
      "Paragraph index :  273\n",
      "Paragraph :  Chris Carter (right-handed hitter)\n",
      "up ^ `` A 's trade RHP Dan Haren to Arizona in eight player deal '' ( Press release ) . Oakland Athletics . December 14 , 2007 . Retrieved July 16 , 2008 . Jump up ^ `` Trevor Cahill and Chris Carter named organizational players of the year '' ( Press release ) . Oakland Athletics . October 10 , 2008 . Retrieved November 23 , 2009 . Jump up ^ `` Chris Carter '' . The Baseball Cube . Retrieved May 20 , 2009 . ^ Jump up to : Winston , Lisa ( January 1 , 2010 ) . `` A 's Carter pays immediate dividends : Slugger earns MiLBY for Overall Minor League Hitter '' . MLB Advanced Media , L.P . Retrieved June 17 , 2011 . Jump up ^ `` A 's Add Four To 40 - Man Roster '' . Retrieved February 17 , 2017 . ^ Jump up to : `` Chris Carter Statistics and History '' . Baseball-Reference.com . Retrieved April 22 , 2015 . Jump up ^ `` Winter Plans '' . San Francisco Chronicle . September 23 , 2010 . Retrieved September 23 , 2010 . Jump up ^ `` Chris Carter Minor League Statistics & History '' . Baseball-Reference.com . Retrieved April 22 , 2015 . Jump up ^ McTaggert , Brian ( February 4 , 2013 ) . `` Astros pick up three players in trade with A 's '' . MLB.com . Retrieved January 15\n",
      "Distance :  0.8843338489532471\n"
     ]
    }
   ],
   "source": [
    "sample_chunks = relevant_contexts[0]\n",
    "for i, chunk in enumerate(sample_chunks['documents'][0]):\n",
    "    print(\"=========\")\n",
    "    print(\"Paragraph index : \", sample_chunks['ids'][0][i])\n",
    "    print(\"Paragraph : \", chunk)\n",
    "    print(\"Distance : \", sample_chunks['distances'][0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feed the context and the questions to `watsonx.ai` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define instructions for the model.\n",
    "\n",
    "**Note:** Please **start with using [watsonx.ai Prompt Lab](https://dataplatform.cloud.ibm.com/wx/home?context=wx)** to find better prompts that provides you the best result on a small subset training records (under `train_data` variable). Make sure to not run an inference of all of `train_data`, as it'll take a long time to get the results. To get a sample from `train_data`, you can use e.g.`train_data.head(n=10)` to get first 10 records, or `train_data.sample(n=10)` to get random 10 records. Only once you have identified the best performing prompt, update this notebook to use the prompt and compute the metrics on the test data.\n",
    "\n",
    "**Action:** Please edit the below cell and add your own prompt here. In the below prompt, we have the instruction (first sentence) and one example included in the prompt.  If you want to change the prompt or add your own examples or more examples, please change the below prompt accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    prompt = f\"Given the provided context:\\n{context}\\n\\nYour answer to the question:\\n{question_text}\"\n",
    "    return prompt\n",
    "prompt_texts = []\n",
    "for context, question_text in zip(relevant_contexts, question_texts):\n",
    "    prompt_text = make_prompt(context, question_text)\n",
    "    prompt_texts.append(prompt_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inspect prompt for sample question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the provided context:\n",
      "{'ids': [['649', '650', '648', '651', '661', '678']], 'embeddings': None, 'documents': [['Safari version history\\n) Since 2016 macOS 10.13 High Sierra 11.0 ( September 19 , 2017 ) Since 2017 Microsoft Windows Windows 2000 3.0. 3 ( August 1 , 2007 ) Unofficial Windows XP SP1 4.0. 3 ( August 11 , 2009 ) 2007 -- 2009 Windows XP SP2 , SP3 5.1. 7 ( May 9 , 2012 ) 2007 -- 2012 Windows Vista Windows 7 2009 -- 2012 Release history ( edit ) Key : Old Beta Version Old Version Supported Version Current Version Current Beta Version Mac ( edit ) Major version Minor version WebKit version Operating System Release date Features Safari 0.8 48 Mac OS X v10. 2 January 7 , 2003 Public Beta . Initial release at Macworld San Francisco . 0.9 73 April 14 , 2003 Public Beta 2 . Tabbed browsing , forms and passwords autofill , browser reset ( removes cookies , cache , etc . ) , Netscape and Mozilla bookmarks importing , improved support for web standards , improved AppleScript support , more localizations . Safari 1 1.0 85 June 23 , 2003 First non-beta release . Safari is now default Mac OS X browser , faster autotabs , support for iSync bookmark synchronization , all Mac OS X languages supported , more AppleScripts to control browser , improved support for web standards . 1.0. 3 85.8. 5 August 13 , 2004 Improves the Safari rendering engine to expand third party application support and delivers the latest security enhancements . 100 Mac OS X', \"Safari version history\\nv10. 3 October 24 , 2003 Released with Mac OS X v10. 3 . Improved speed , improved support for web standards , improved CSS support . 125 February 2 , 2004 Improved compatibility with websites and web applications . Support for personal certificate authentication . Full keyboard access for navigation . Ability to resume interrupted downloads . Sajax and LiveConnect support . XMLHttpRequest support . 1.3 312 April 15 , 2005 Released with Mac OS X v10. 3.9 . Included most of the rendering speed and website compatibility improvements that were developed for 2.0. designMode support . 1.3. 1 312.3 August 29 , 2005 Improves website compatibility , application stability and support for 3rd party web applications . 1.3. 2 312.5 January 11 , 2006 Improves website compatibility , application stability and support for 3rd party web applications . Requires 1.3. 1 in order to install . 1.3. 2 312.6 January 12 , 2006 Requires earlier version in order to install . Safari 2 2.0 412 Mac OS X v10. 4 April 29 , 2005 Dubbed `` Safari RSS . '' Released with Mac OS X v10. 4 . Improved rendering speed and website compatibility . Integrated RSS and Atom reader . Integrated PDF viewer . Private Browsing mode and Parental Controls . Ability to save complete websites using the proprietary WebArchive format . 2.0. 2 416.11 October 31 , 2005 Safari passes the Web Standards Project Acid2 test . 2.0. 4 419.3 January 10 , 2006 Most widely\", 'Safari version history\\nSafari version history - Wikipedia Safari version history Jump to : navigation , search The version history of Safari spans from 2003 to the present from its initial preview release for OS X at Macworld to becoming cross-platform with versions for Windows and iOS . Contents ( hide ) 1 Version compatibility 2 Release history 2.1 Mac 2.2 Windows 2.3 iOS 3 See also 4 References 5 External links Version compatibility ( edit ) Operating system Operating system version Latest Safari version Support macOS Mac OS X 10.2 Jaguar 1.0. 3 ( August 13 , 2004 ) 2003 -- 2005 Mac OS X 10.3 Panther 1.3. 2 ( January 11 , 2006 ) 2003 -- 2007 Mac OS X 10.4 Tiger 4.1. 3 ( November 18 , 2010 ) 2005 -- 2010 Mac OS X 10.5 Leopard 5.0. 6 ( July 20 , 2011 ) 2007 -- 2011 Mac OS X 10.6 Snow Leopard 5.1. 10 ( September 12 , 2013 ) 2009 -- 2013 Mac OS X 10.7 Lion 6.1. 6 ( August 13 , 2014 ) 2011 -- 2014 OS X 10.8 Mountain Lion 6.2. 8 ( August 13 , 2015 ) 2012 -- 2015 OS X 10.9 Mavericks 9.1. 3 ( September 1 , 2016 ) 2013 -- 2016 OS X 10.10 Yosemite 10.1. 2 ( July 19 , 2017 ) 2014 - 2017 OS X 10.11 El Capitan 11.0 ( September 19 , 2017 ) Since 2015 macOS 10.12 Sierra 11.0 ( September 19 , 2017', \"Safari version history\\ndistributed version of Safari 2 , available only as part of Mac OS X Update 10.4. 4 . Last stable version released before version 3.0 . Last Mac OS X-exclusive version . Safari 3 3.0 522.11 June 11 , 2007 Public beta . Initial release at the Apple Worldwide Developers Conference . Version for Mac OS X v10. 4.9 and later . Improved searching within web pages . Drag and drop tabs , and the ability to save a group of tabs as a single bookmark . Live resizing of text input fields . Bonjour support for bookmarks . Initial SVG support . 3.0. 2 522.12 June 22 , 2007 Public beta . 3.0. 3 522.12. 1 July 31 , 2007 Public beta . Latest security updates . 3.0. 4 523.10 Mac OS X v10. 4 - 10.5 October 26 , 2007 Officially released with Mac OS X v10. 5 out of beta . Includes the ability to re-arrange tabs by dragging , improved web standards support , the ability to display SVG images , and integration with the Dashboard , allowing users to create widgets from ordinary web pages . For web developers , Safari 3 includes a new `` Web Inspector '' similar to the DOM Inspector extension for Mozilla Firefox . November 14 , 2007 Officially released for Mac OS X v10. 4.11 . 3.1 525.13 March 18 , 2008 Introduces support for CSS Web fonts and animations and improves support for SVG and HTML5 media .\", 'Safari version history\\n10.8 September 18 , 2014 Security update . 6.2. 1 December 4 , 2014 Security update . 6.2. 2 December 11 , 2014 Security update . 6.2. 3 January 27 , 2015 Security update . 6.2. 4 March 17 , 2015 Security update . 6.2. 5 April 8 , 2015 Security update . 6.2. 6 May 6 , 2015 Security update . 6.2. 7 June 30 , 2015 Security update . 6.2. 8 537.85. 17 August 13 , 2015 Security update . Safari 7 7.0 537.71 OS X 10.9 October 22 , 2013 Bundled with OS X 10.9 Developer Preview 1. New Sidebar with Shared Links , Bookmarks and Reading List . Redesigned Top Sites . Nitro Tiered JIT , Fast Start and power - saving technologies . 7.0. 1 537.73. 11 December 16 , 2013 Security update . Bundled with OS X 10.9. 1 7.0. 2 February 25 , 2014 Security update . 7.0. 3 537.75. 14 April 1 , 2014 Security update . Bundled with OS X 10.9. 3 7.0. 4 537.76. 4 May 21 , 2014 Security update . 7.0. 5 537.77. 4 June 30 , 2014 Security update . Bundled with OS X 10.9. 4 7.0. 6 537.78. 2 August 13 , 2014 Security update . Bundled with OS X 10.9. 5 7.1 September 18 , 2014 Security update . 7.1. 1 December 4 , 2014 Security update . 7.1. 2 December 11 , 2014 Security update . 7.1. 3 January 27 , 2015 Security update', \"Safari version history\\n27 , 2017 . Retrieved April 2 , 2017 . Jump up ^ `` About the security content of Safari 10.1. 1 '' . May 15 , 2017 . Retrieved July 23 , 2017 . Jump up ^ Rossignol , Joe . `` Safari 11 Released for macOS Sierra and OS X El Capitan '' . Retrieved 2017 - 09 - 22 . Jump up ^ John Wilander ( June 5 , 2017 ) . `` Intelligent Tracking Prevention '' . WebKit Blog . Retrieved September 22 , 2017 . Jump up ^ `` Safari 11.0 '' . June 22 , 2017 . Retrieved September 22 , 2017 . Jump up ^ `` About Safari 3 Beta 3.0. 4 Security Update v1. 1 '' . Apple Inc . Retrieved June 12 , 2008 . Jump up ^ Justin Berka ( August 25 , 2008 ) . `` New betas of 10.5. 5 and Safari 4 seeded to developers '' . Ars Technica . Retrieved August 25 , 2008 . External links ( edit ) Safari -- official site at Apple iOS and iOS - based products History Outline Hardware Apple TV Apple Watch Series 2 Series 3 iPad 1st 2nd 3rd 4th Air Air 2 2017 iPad Mini 1st iPad Pro iPhone 1st 3G 3GS 4S 5 5C 5S 6 & 6 Plus 6S & 6S Plus SE 7 & 7 Plus 8 & 8 Plus X iPod Touch 1st 2nd 3rd 4th 5th 6th Software AirDrop AirPlay AirPrint CarPlay\"]], 'metadatas': [[{'title': 'Safari version history', 'id': 649}, {'title': 'Safari version history', 'id': 650}, {'title': 'Safari version history', 'id': 648}, {'title': 'Safari version history', 'id': 651}, {'title': 'Safari version history', 'id': 661}, {'title': 'Safari version history', 'id': 678}]], 'distances': [[0.5248146057128906, 0.5669463276863098, 0.5954746007919312, 0.6066253185272217, 0.6110373735427856, 0.6305090188980103]]}\n",
      "\n",
      "Your answer to the question:\n",
      "what is the latest version of safari on mac?\n"
     ]
    }
   ],
   "source": [
    "print(prompt_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "parameters: {\n",
    "  \"decoding_method\": \"sample\",\n",
    "  \"max_new_tokens\": 20,\n",
    "  \"temperature\": 0.2,\n",
    "  \"top_k\": 100,\n",
    "  \"top_p\": 0.9,\n",
    "  \"repetition_penalty\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Initialize the `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "\n",
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate a retrieval-augmented response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Execution of this cell could take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for prompt_text in prompt_texts:\n",
    "    results.append(model.generate_text(prompt=prompt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question =  who did chris carter play for last year\n",
      "Answer =  Milwaukee Brewers\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Milwaukee Brewers\n",
      "\n",
      "\n",
      "Question =  what is the latest version of safari on mac\n",
      "Answer =  Safari 11\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Safari 11\n",
      "\n",
      "\n",
      "Question =  when did bucharest become the capital of romania\n",
      "Answer =  1862\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1862\n",
      "\n",
      "\n",
      "Question =  who did jeffrey dean morgan play on supernatural\n",
      "Answer =  John Winchester\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  John Eric Winchester\n",
      "\n",
      "\n",
      "Question =  who is the shortest man that ever lived\n",
      "Answer =  Chandra Bahadur Dangi\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Chandra Bahadur Dangi\n",
      "\n",
      "\n",
      "Question =  how many seconds do you have to throw a grenade\n",
      "Answer =  4\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  4 and 5 seconds\n",
      "\n",
      "\n",
      "Question =  who is known as a father of indian cricket\n",
      "Answer =  Buchi Babu Naidu\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  M. Suryanarayan\n",
      "\n",
      "\n",
      "Question =  what is the name of the period in japanese history that began in 1868\n",
      "Answer =  Meiji\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Meiji\n",
      "\n",
      "\n",
      "Question =  harold and kumar go to white castle where was it filmed\n",
      "Answer =  Toronto\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Toronto , Ontario , Canada\n",
      "\n",
      "\n",
      "Question =  how many games have the capitals won in the playoffs\n",
      "Answer =  70\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  two\n",
      "\n",
      "\n",
      "Question =  what is the best selling nintendo game of all time\n",
      "Answer =  Super Mario Bros\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Wii Sports\n",
      "\n",
      "\n",
      "Question =  korean movie about a man on an island\n",
      "Answer =  Castaway on the Moon\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Castaway on the Moon\n",
      "\n",
      "\n",
      "Question =  who plays lorelai in hannah montana the movie\n",
      "Answer =  Melora Hardin\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Melora Hardin\n",
      "\n",
      "\n",
      "Question =  what season of greys anatomy was the plane crash\n",
      "Answer =  seventh season\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  the eighth season\n",
      "\n",
      "\n",
      "Question =  who made call of duty black ops 2\n",
      "Answer =  Treyarch\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Treyarch\n",
      "\n",
      "\n",
      "Question =  when was the last solar eclipse seen in north america\n",
      "Answer =  August 21, 2017\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  August 21 , 2017\n",
      "\n",
      "\n",
      "Question =  who is hosting the fifa world cup in 2022\n",
      "Answer =  Qatar\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Qatar\n",
      "\n",
      "\n",
      "Question =  what is the record for wins in major league baseball\n",
      "Answer =  2,632\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  116\n",
      "\n",
      "\n",
      "Question =  big boss 2 telugu set location in hyderabad\n",
      "Answer =  hyderabad\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Annapurna Studios , Hyderabad\n",
      "\n",
      "\n",
      "Question =  who did the us support in the korean war\n",
      "Answer =  South Korea\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  South Korea\n",
      "\n",
      "\n",
      "Question =  what is the caterpillar smoking in alice in wonderland\n",
      "Answer =  hookah\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  a hookah\n",
      "\n",
      "\n",
      "Question =  how much aid does us give to other countries\n",
      "Answer =  0.7 percent of the budget put towards foreign aid\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  $43.10 billion\n",
      "\n",
      "\n",
      "Question =  who plays jake on two and a half\n",
      "Answer =  Jeremy Allen White\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Angus Turner Jones\n",
      "\n",
      "\n",
      "Question =  what do you call a bundle of hay\n",
      "Answer =  haystack\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  bales\n",
      "\n",
      "\n",
      "Question =  how many levels are there in science olympiad\n",
      "Answer =  two levels\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  two\n",
      "\n",
      "\n",
      "Question =  where are the singers of florida georgia line from\n",
      "Answer =  Monroe , Georgia\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Monroe , Georgia::Ormond Beach , Florida\n",
      "\n",
      "\n",
      "Question =  who sings lead on wouldnt it be nice\n",
      "Answer =  Brian Wilson\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Brian Wilson::Mike Love\n",
      "\n",
      "\n",
      "Question =  who is the main character in shadow of mordor\n",
      "Answer =  Talion\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Talion\n",
      "\n",
      "\n",
      "Question =  where are the next olympics to be held\n",
      "Answer =  Pyeongchang\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Tokyo::Beijing\n",
      "\n",
      "\n",
      "Question =  when did game of thrones season 7 start\n",
      "Answer =  July 16 , 2017\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  July 16 , 2017\n",
      "\n",
      "\n",
      "Question =  when does hook show up in once upon a time\n",
      "Answer =  season 2\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  The Crocodile\n",
      "\n",
      "\n",
      "Question =  when was the last time georgia tech won a national championship\n",
      "Answer =  1990\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1990\n",
      "\n",
      "\n",
      "Question =  who plays victor in days of our lives\n",
      "Answer =  John Aniston\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  John Anthony Aniston\n",
      "\n",
      "\n",
      "Question =  who won the last triple crown in baseball\n",
      "Answer =  Miguel Cabrera\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Miguel Cabrera\n",
      "\n",
      "\n",
      "Question =  when does the football transfer window open in 2018\n",
      "Answer =  17 May\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  August 9\n",
      "\n",
      "\n",
      "Question =  what episode of mr young do adam and echo kiss\n",
      "Answer =  Mr. Shakespeare\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  `` Mr. First Impression ''\n",
      "\n",
      "\n",
      "Question =  when is game of thrones season 7 episode 7 releasing\n",
      "Answer =  August 27\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  July 16 , 2017\n",
      "\n",
      "\n",
      "Question =  who is the architect of sheikh zayed mosque\n",
      "Answer =  Yousef Abdelky\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Yousef Abdelky\n",
      "\n",
      "\n",
      "Question =  who is the director of iron man 3\n",
      "Answer =  Shane Black\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Shane Black\n",
      "\n",
      "\n",
      "Question =  who is one of the first german composers that we know about\n",
      "Answer =  Adam von Fulda\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Adam von Fulda\n",
      "\n",
      "\n",
      "Question =  where do they move to in cheaper by the dozen\n",
      "Answer =  Evanston\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Evanston , IL\n",
      "\n",
      "\n",
      "Question =  who played bass on and justice for all\n",
      "Answer =  Jason Newsted\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Jason Newsted\n",
      "\n",
      "\n",
      "Question =  zen and the art of motorcycle maintenance bikes\n",
      "Answer =  Honda CB77\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  CB77 Super Hawk\n",
      "\n",
      "\n",
      "Question =  when did texas become part of united states\n",
      "Answer =  December 29 , 1845\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  1845\n",
      "\n",
      "\n",
      "Question =  the atlantoaxial joint is an example of what type of joint\n",
      "Answer =  a pivot joint\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  a pivot joint\n",
      "\n",
      "\n",
      "Question =  what is the fastest roller coaster in california\n",
      "Answer =  Goliath\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Formula Rossa\n",
      "\n",
      "\n",
      "Question =  when did they start to build the great wall of china\n",
      "Answer =  771 -- 476 BC\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  771 -- 476 BC\n",
      "\n",
      "\n",
      "Question =  what type of reaction is the rusting of iron\n",
      "Answer =  electrochemical\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  electrochemical\n",
      "\n",
      "\n",
      "Question =  where do the flyers play their home games\n",
      "Answer =  Wells Fargo Center\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Wells Fargo Center\n",
      "\n",
      "\n",
      "Question =  where does something old something new something borrowed something blue come from\n",
      "Answer =  Lancashire\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Lancashire\n",
      "\n",
      "\n",
      "Question =  Where was carter born?\n",
      "Answer =  Redwood City\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  Redwood\n",
      "\n",
      "\n",
      "Question =  which school did chris carter played basketball?\n",
      "Answer =  Rancho High School\n",
      "Expected Answer(s) (may not be appear with exact wording in the dataset) =  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, result in enumerate(results):\n",
    "    print(\"Question = \", test_data.iloc[idx]['question'])\n",
    "    print(\"Answer = \", result)\n",
    "    print(\"Expected Answer(s) (may not be appear with exact wording in the dataset) = \", test_data.iloc[idx]['answers'])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"score\"></a>\n",
    "## Calculate rougeL metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample notebook `rouge_score` module was used for rougeL calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rouge Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note:** The Rouge (Recall-Oriented Understudy for Gisting Evaluation) metric is a set of evaluation measures used in natural language processing (NLP) and specifically in text summarization and machine translation tasks. The Rouge metrics are designed to assess the quality of generated summaries or translations by comparing them to one or more reference texts.\n",
    "\n",
    "The main idea behind Rouge is to measure the overlap between the generated summary (or translation) and the reference text(s) in terms of n-grams or longest common subsequences. By calculating recall, precision, and F1 scores based on these overlapping units, Rouge provides a quantitative assessment of the summary's content overlap with the reference(s).\n",
    "\n",
    "Rouge-1 focuses on individual word overlap, Rouge-2 considers pairs of consecutive words, and Rouge-L takes into account the ordering of words and phrases. These metrics provide different perspectives on the similarity between two texts and can be used to evaluate different aspects of summarization or text generation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def get_rouge_score(predictions, references):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "    aggregate_score = defaultdict(list)\n",
    "\n",
    "    for result, ref in zip(predictions, references):\n",
    "        for key, val in scorer.score(result, ref).items():\n",
    "            aggregate_score[key].append(val.fmeasure)\n",
    "\n",
    "    scores = {}\n",
    "    for key in aggregate_score:\n",
    "        scores[key] = np.mean(aggregate_score[key])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.6270146520146519, 'rouge2': 0.32499999999999996, 'rougeL': 0.6270146520146519, 'rougeLsum': 0.6270146520146519}\n"
     ]
    }
   ],
   "source": [
    "print(get_rouge_score(results, test_data.answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright  2023 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
